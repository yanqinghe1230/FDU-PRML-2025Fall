{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d604ba",
   "metadata": {},
   "source": [
    "# <center>练习二——线性分类</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7eb3019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关的库\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f61f907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 数据加载\n",
    "names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', \n",
    "         'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', \n",
    "         'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class']\n",
    "\n",
    "data_path = \"data/breast-cancer-wisconsin.data\"\n",
    "data = pd.read_csv(data_path, names=names)\n",
    "\n",
    "# 2 数据预处理\n",
    "# 2.1 数据清洗：去除含缺失值的样本\n",
    "data = data.replace(to_replace=\"?\", value=np.nan)  \n",
    "data = data.dropna()\n",
    "\n",
    "# 2.2 将特征列和标签列转换为数值类型\n",
    "data.iloc[:, 1:] = data.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
    "data = data.dropna() \n",
    "\n",
    "x = data.iloc[:, 1:10].values.astype(np.float64)  \n",
    "y = data[\"Class\"].values.astype(int) \n",
    "y = np.where(y == 4, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53b56013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 数据集划分\n",
    "def train_test_split_manual(X, y, test_size=0.25, random_state=2025):\n",
    "    \"\"\"手动实现训练集和测试集的划分\"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "    n_test = int(n_samples * test_size)\n",
    "    \n",
    "    # 生成随机索引\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    test_indices = indices[:n_test]\n",
    "    train_indices = indices[n_test:]\n",
    "    \n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ac30b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 特征标准化\n",
    "class StandardScaler:\n",
    "    # TODO\n",
    "    # 实现特征标准化\n",
    "    # 标准化公式: z = (x - mean) / std\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"计算均值和标准差\"\"\"\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        self.std_ = np.std(X, axis=0)\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"使用均值和标准差进行标准化\"\"\"\n",
    "        return (X - self.mean_) / self.std_\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"拟合并转换\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98db608",
   "metadata": {},
   "source": [
    "## 逻辑回归\n",
    "\n",
    "### 模型形式\n",
    "$h_\\theta(x) = \\frac{1}{1 + e^{-\\theta x}}$\n",
    "\n",
    "* $x$：输入特征向量\n",
    "* $\\theta$：模型参数\n",
    "* $h_\\theta(x)$：预测结果（属于正类的概率）\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{class} =\n",
    "\\begin{cases}\n",
    "1, & \\text{if } h_\\theta(x) \\ge 0.5 \\\\\n",
    "0, & \\text{if } h_\\theta(x) < 0.5\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### 损失函数：\n",
    "\n",
    "$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m}\\Big[y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)}))\\Big]$\n",
    "\n",
    "\n",
    "### 优化：梯度下降\n",
    "\n",
    "$\\theta := \\theta - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta}$\n",
    "\n",
    "其中 $\\alpha$ 为学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 实现逻辑回归\n",
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "    参数:\n",
    "        learning_rate: 学习率\n",
    "        n_iterations: 迭代次数\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def sigmoid(self, z: np.ndarray) -> np.ndarray:\n",
    "        # sigmoid(z) = 1 / (1 + e^(-z))\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def compute(self, X: np.ndarray, y: np.ndarray):\n",
    "        m=X.shape[0]\n",
    "\n",
    "        z=np.dot(X,self.weights)+self.bias\n",
    "        A=self.sigmoid(z)\n",
    "        cost= -1/m * np.sum(y*np.log(A)+(1-y)*np.log(1-A))\n",
    "\n",
    "        dz=A-y\n",
    "        dw=(1.0/m)*np.dot(X.T,dz)\n",
    "        db=(1.0/m)*np.sum(dz)\n",
    "\n",
    "        return dw,db,cost\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        # TODO: 训练模型\n",
    "        # 使用批量梯度下降法（BatchGradientDescent，BGD）优化权重和偏置\n",
    "            \n",
    "        # 提示:\n",
    "        # 1. 初始化权重和偏置\n",
    "        # 2. 进行n_iterations次迭代\n",
    "        # 3. 每次迭代:\n",
    "        #     step1. 计算预测值\n",
    "        #     step2. 计算梯度\n",
    "        #     step3. 更新参数\n",
    "        self.weights=np.zeros(X.shape[1],dtype=float)\n",
    "        self.bias=0.0\n",
    "\n",
    "        for i in range(self.n_iterations):\n",
    "            dw,db,cost=self.compute(X,y)\n",
    "            self.weights=self.weights - self.learning_rate*dw\n",
    "            self.bias=self.bias - self.learning_rate*db\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    def predict(self, X: np.ndarray, threshold: float = 0.5) -> np.ndarray:\n",
    "        # TODO: 预测\n",
    "        # 提示:\n",
    "        # 1. 进行线性运算\n",
    "        # 2. 进行sigmoid计算\n",
    "        # 3. 将结果与阈值进行比较\n",
    "        z=np.dot(X,self.weights)+self.bias\n",
    "        A=self.sigmoid(z)\n",
    "        y_pred=(A>=threshold).astype(int)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b71a6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "        获得评测指标\n",
    "    \"\"\"\n",
    "    def recall_score(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        计算召回率\n",
    "        召回率 = TP / (TP + FN)\n",
    "        \"\"\"\n",
    "        TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "        FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "        return TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "\n",
    "    def precision_score(y_true, y_pred):\n",
    "        \"\"\"精确率 = TP / (TP + FP)\"\"\"\n",
    "        TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "        FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "        return TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "        \n",
    "    def accuracy_score(y_true, y_pred):\n",
    "        \"\"\"准确率 = (TP + TN) / 总数\"\"\"\n",
    "        return np.mean(y_true == y_pred)\n",
    "\n",
    "\n",
    "    def confusion_matrix(y_true, y_pred):\n",
    "        \"\"\"混淆矩阵\"\"\"\n",
    "        TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "        FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "        FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "        TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "        \n",
    "        return np.array([[TN, FP], [FN, TP]])\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return recall, precision, accuracy, cm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1445aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "乳腺癌诊断预测 - 逻辑回归实现\n",
      "============================================================\n",
      "\n",
      "数据集信息:\n",
      "训练集样本数: 513\n",
      "测试集样本数: 170\n",
      "特征数: 9\n",
      "\n",
      "开始训练模型...\n",
      "\n",
      "============================================================\n",
      "模型评估结果\n",
      "============================================================\n",
      "\n",
      "召回率 (Recall):    0.9831 (98.31%)\n",
      "精确率 (Precision): 0.9667 (96.67%)\n",
      "准确率 (Accuracy):  0.9824 (98.24%)\n",
      "\n",
      "混淆矩阵:\n",
      "              预测负类  预测正类\n",
      "实际负类         109        2\n",
      "实际正类           1       58\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    print(\"=\" * 60)\n",
    "    print(\"乳腺癌诊断预测 - 逻辑回归实现\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 划分数据集\n",
    "    X_train, X_test, y_train, y_test = train_test_split_manual(x, y, test_size=0.25, random_state=22)\n",
    "    \n",
    "    print(f\"\\n数据集信息:\")\n",
    "    print(f\"训练集样本数: {X_train.shape[0]}\")\n",
    "    print(f\"测试集样本数: {X_test.shape[0]}\")\n",
    "    print(f\"特征数: {X_train.shape[1]}\")\n",
    "    \n",
    "    # 特征标准化\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    print(\"\\n开始训练模型...\")\n",
    "    # 训练逻辑回归模型\n",
    "    model = LogisticRegression(learning_rate=0.01, n_iterations=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 评估\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"模型评估结果\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    recall, precision, accuracy, cm = get_metrics(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n召回率 (Recall):    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "    print(f\"精确率 (Precision): {precision:.4f} ({precision*100:.2f}%)\")\n",
    "    print(f\"准确率 (Accuracy):  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\n混淆矩阵:\")\n",
    "    print(f\"              预测负类  预测正类\")\n",
    "    print(f\"实际负类        {cm[0,0]:4d}     {cm[0,1]:4d}\")\n",
    "    print(f\"实际正类        {cm[1,0]:4d}     {cm[1,1]:4d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a22aec6",
   "metadata": {},
   "source": [
    "## 相关问题\n",
    "\n",
    "### 问题一：逻辑回归的数学原理\n",
    "1. sigmoid函数有什么重要的数学性质？\n",
    "\n",
    "2. 逻辑回归使用什么损失函数，为什么不能使用均方误差（MSE）？\n",
    "\n",
    "**Answer**\n",
    "\n",
    "1. sigmoid函数的值域是(0,1)，可以将整个实数区间的值都映射到(0,1)之间表示概率。并且sigmoid函数无限次可导，且导数形式简单，便于梯度计算。\n",
    "\n",
    "2. 逻辑回归使用交叉熵损失函数。当预测值接近0或1时，sigmoid函数的梯度接近0，若使用MSE，则损失函数的梯度也很小，会导致参数更新缓慢。\n",
    "\n",
    "### 问题二：召回率的理解\n",
    "\n",
    "在本次作业中，我们引入召回率（Recall）作为模型评估的重要指标。请简单阐明在实验数据集上使用召回率的意义。\n",
    "\n",
    "**Answer**\n",
    "\n",
    "本次作业中进行的是对乳腺癌诊断预测的线性回归。对于临床病症检测，应该要尽可能找到所有正确样本不能有遗漏。若不将召回率作为模型评估的指标之一，即使正确率很高，也可能有许多患病样本未被预测出来，导致病人无法及时诊治。\n",
    "\n",
    "\n",
    "### 问题三：softmax回归的基础概念\n",
    "1. softmax函数的核心作用是什么？\n",
    "2. softmax与普通的归一化（如除以总和）有什么本质区别？\n",
    "3. softmax的计算公式如下，但在实现时可能面临指数过大带来的溢出问题，可以怎么处理？\n",
    "\n",
    "   $$\n",
    "   \\mathrm{softmax}(\\mathbf{x})_i = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}}, \\quad i=1,\\dots ,n\n",
    "   $$\n",
    "\n",
    "**Answer**\n",
    "\n",
    "1. softmax函数将实数向量映射到(0,1)区间中且所有输出和为1，相当于将实数向量转换为概率分布，用于多分类问题的最后一层，输出每个类别的概率\n",
    "\n",
    "2. a. 即使输入是负数，softmax函数依然能保证输出概率为正，普通的归一化则有可能产生负概率\n",
    "   b. softmax通过指数运算放大差异，使得最大值对应的概率更加突出\n",
    "   c. softmax函数处处可导，便于计算梯度与反向传播\n",
    "\n",
    "3. 可以同时将所有元素减去最大值，使最大元素变为0，其余元素变为负数，以避免指数过大导致溢出。同时由于指数的运算性质，减去后依然在数学上等价。\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c1e6f",
   "metadata": {},
   "source": [
    "### 选做内容： 分析逻辑回归预测时的阈值（threshold）参数对实验结果的影响\n",
    "\n",
    "首先测试回归模型在三个不同阈值下的预测结果以及对应评测指标成果，具体如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f3016f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "模型评估结果: 阈值 = 0.30\n",
      "============================================================\n",
      "\n",
      "召回率 (Recall):    1.0000 (100.00%)\n",
      "精确率 (Precision): 0.8806 (88.06%)\n",
      "准确率 (Accuracy):  0.9529 (95.29%)\n",
      "\n",
      "============================================================\n",
      "模型评估结果: 阈值 = 0.50\n",
      "============================================================\n",
      "\n",
      "召回率 (Recall):    0.9831 (98.31%)\n",
      "精确率 (Precision): 0.9667 (96.67%)\n",
      "准确率 (Accuracy):  0.9824 (98.24%)\n",
      "\n",
      "============================================================\n",
      "模型评估结果: 阈值 = 0.70\n",
      "============================================================\n",
      "\n",
      "召回率 (Recall):    0.8644 (86.44%)\n",
      "精确率 (Precision): 1.0000 (100.00%)\n",
      "准确率 (Accuracy):  0.9529 (95.29%)\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':    \n",
    "    # 划分数据集\n",
    "    X_train, X_test, y_train, y_test = train_test_split_manual(x, y, test_size=0.25, random_state=22)\n",
    "    \n",
    "    # 特征标准化\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # 训练逻辑回归模型\n",
    "    model = LogisticRegression(learning_rate=0.01, n_iterations=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 预测\n",
    "    for threshold in [0.3, 0.5, 0.7]:\n",
    "        y_pred = model.predict(X_test,threshold)\n",
    "\n",
    "        # 评估\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"模型评估结果: 阈值 = {:.2f}\".format(threshold))\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        recall, precision, accuracy, cm = get_metrics(y_test, y_pred)\n",
    "\n",
    "        print(f\"\\n召回率 (Recall):    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "        print(f\"精确率 (Precision): {precision:.4f} ({precision*100:.2f}%)\")\n",
    "        print(f\"准确率 (Accuracy):  {accuracy:.4f} ({accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3696a096",
   "metadata": {},
   "source": [
    "以上结果显示：随着阈值升高，召回率逐步降低，精确率逐步升高，而当阈值居中(0.5)时，准确率最高。\n",
    "\n",
    "因为阈值较低会倾向于将样本分为正类，导致许多样本把握没那么大的样本会被误分类为正类；反之阈值较高会倾向于将样本分为负类，只有非常有把握的样本会被分类为正类。\n",
    "\n",
    "应该根据数据集场景选择适当的阈值：\n",
    "1. 对于如癌症筛查、临床检测的场景下，应该选择较低阈值以避免患病的患者被漏诊\n",
    "\n",
    "2. 对于如垃圾邮件过滤这类需要高精确度的场景下，应该选择较高阈值以减少误报"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
