<!DOCTYPE html><html><head>
      <title>实验二报告模板</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:////home/heeq/.vscode-server/extensions/shd101wyy.markdown-preview-enhanced-0.8.20/crossnote/dependencies/katex/katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1 id="模式识别与机器学习---实验2"><strong>模式识别与机器学习 -- 实验2</strong> </h1>
<p>本实验包含以下部分：</p>
<ul>
<li>
<p>softmax （50%）</p>
</li>
<li>
<p>svm （50%）</p>
</li>
</ul>
<h2 id="softmax"><strong>softmax</strong> </h2>
<p>1 手动实现 Softmax 函数 （15%）</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-def">def</span> <span class="token function">my_softmax</span><span class="token punctuation">(</span>logits<span class="token punctuation">)</span><span class="token punctuation">:</span>
    max_<span class="token operator">=</span>logits<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    logits<span class="token operator">=</span>logits<span class="token operator">-</span>max_
    exp_logits<span class="token operator">=</span>torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>logits<span class="token punctuation">)</span>
    sum_exp<span class="token operator">=</span>exp_logits<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    probs<span class="token operator">=</span>exp_logits<span class="token operator">/</span>sum_exp
    <span class="token keyword keyword-return">return</span> probs
</code></pre><p>首先找出每一行的最大值，每一行减去该行最大值之后计算指数，最后通过除以每一行的和实现归一化，得到预测的概率。</p>
<p>2 创建自定义 Softmax 层  （15%）</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-class">class</span> <span class="token class-name">MySoftmax</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> dim
    
    <span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-return">return</span> my_softmax<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre><p>先将softmax函数封装成一个softmax层，在该层中调用之前定义的<code>soft_max</code>函数计算预测概率。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-class">class</span> <span class="token class-name">CustomSoftmaxModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden1<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> hidden2<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>flatten <span class="token operator">=</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_relu_stack<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span>hidden1<span class="token punctuation">)</span><span class="token punctuation">,</span> 
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden1<span class="token punctuation">,</span>hidden2<span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden2<span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            MySoftmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
    <span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        probs<span class="token operator">=</span>self<span class="token punctuation">.</span>linear_relu_stack<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword keyword-return">return</span> probs
</code></pre><p>然后定义了使用softmax层的网络，与标准模型的差别就在于调用了soft_max层用于计算预测概率的输出。</p>
<p>3 参数调优实验（无需给出代码）</p>
<p>4 提交实验结果，只需截图最后的实验结果汇总和最佳模型的配置即可（20%）</p>
<p><strong>实验结果汇总</strong></p>
<p><img src="image.png" alt="alt text"></p>
<p><strong>最佳模型配置及结果</strong></p>
<p><img src="image-1.png" alt="alt text"></p>
<h2 id="svm"><strong>svm</strong> </h2>
<h3 id="一-损失和梯度的计算">一、损失和梯度的计算 </h3>
<h4 id="1-循环实现中的梯度计算10">1, 循环实现中的梯度计算（10%） </h4>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-def">def</span> <span class="token function">svm_loss_naive</span><span class="token punctuation">(</span>W<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> reg<span class="token punctuation">)</span><span class="token punctuation">:</span>
    dW <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>W<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment">#初始化权重为0</span>

    num_classes <span class="token operator">=</span> W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    num_train <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    loss <span class="token operator">=</span> <span class="token number">0.0</span>

    <span class="token keyword keyword-for">for</span> i <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_train<span class="token punctuation">)</span><span class="token punctuation">:</span>
        scores <span class="token operator">=</span> X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">)</span> <span class="token comment">#计算每一类别的得分</span>
        correct_class_score <span class="token operator">=</span> scores<span class="token punctuation">[</span>y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment">#确定正确类的得分</span>
        count<span class="token operator">=</span><span class="token number">0</span> <span class="token comment">#用于计数有多少类别对应的margin大于0</span>
        <span class="token keyword keyword-for">for</span> j <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword keyword-if">if</span> j <span class="token operator">==</span> y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span>
                <span class="token keyword keyword-continue">continue</span>
            margin <span class="token operator">=</span> scores<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">-</span> correct_class_score <span class="token operator">+</span> <span class="token number">1</span>  <span class="token comment"># note delta = 1</span>
            <span class="token keyword keyword-if">if</span> margin <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token comment">#margin大于0说明当前类别与正确类别界限模糊，计入损失</span>
                loss <span class="token operator">+=</span> margin
                count<span class="token operator">+=</span><span class="token number">1</span>
                dW<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token operator">+=</span>X<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        dW<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">-=</span>count<span class="token operator">*</span>X<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    dW<span class="token operator">/=</span>num_train        
    dW <span class="token operator">+=</span> <span class="token number">2</span> <span class="token operator">*</span> reg <span class="token operator">*</span> W
    loss <span class="token operator">/=</span> num_train 
    loss <span class="token operator">+=</span> reg <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>W <span class="token operator">*</span> W<span class="token punctuation">)</span>
    <span class="token keyword keyword-return">return</span> loss<span class="token punctuation">,</span> dW
</code></pre><p>整体思路是：每一次训练中，计算每一类别的得分，然后遍历每一类别比较当前类别得分和正确类别得分之间的差距。如果计算的margin大于0，则说明当前类别与正确类别预测错误或界限模糊，将其计入损失。<br>
对于梯度的计算：<br>
对于每个样本i和类别j，考虑损失函数对<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>求导，当margin大于0时，计入损失的函数部分是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>j</mi></msub><mo>−</mo><msub><mi>s</mi><mrow><mi>y</mi><mi>i</mi></mrow></msub><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">s_j-s_{yi}+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>，并且<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>j</mi></msub><mo>=</mo><mi>X</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo>∗</mo><mi>W</mi><mo stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">s_j=X[i]*W[j]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span></span></span></span>，故对于这些类别，产生的梯度为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">X[i]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span></span></span></span>。对于margin小于等于0的类别，计入损失函数为0，故不产生梯度。<br>
对于正确类别，对于每一个margin大于0的类别，都会产生一次梯度，因此计入的梯度为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo separator="true">⋅</mo><mi>X</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">-count·X[i]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord mathnormal">co</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span></span></span></span>。</p>
<h4 id="2-向量实现中的损失计算和梯度计算15">2, 向量实现中的损失计算和梯度计算（15%） </h4>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-def">def</span> <span class="token function">svm_loss_vectorized</span><span class="token punctuation">(</span>W<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> reg<span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> <span class="token number">0.0</span>
    dW <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>W<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    N<span class="token operator">=</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    scores<span class="token operator">=</span>X<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">)</span>

    correct_scores<span class="token operator">=</span>scores<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">,</span>y<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment">#找到所有正确类别对应的分数</span>
    margins<span class="token operator">=</span>scores<span class="token operator">-</span>correct_scores<span class="token operator">+</span><span class="token number">1</span> <span class="token comment">#计算得到margin矩阵，形状为(N,C)</span>
    margins<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">,</span>y<span class="token punctuation">]</span><span class="token operator">=</span><span class="token number">0</span> <span class="token comment">#将正确类别的margin'置为0</span>
    margins<span class="token operator">=</span>np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>margins<span class="token punctuation">)</span> <span class="token comment">#将小于0的margin置为0</span>
    loss<span class="token operator">=</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>margins<span class="token punctuation">)</span><span class="token operator">/</span>N <span class="token comment">#计算损失</span>
    loss<span class="token operator">+=</span>reg<span class="token operator">*</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>W<span class="token operator">*</span>W<span class="token punctuation">)</span>
    binary<span class="token operator">=</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>margins<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment">#将原有margin矩阵复制一份</span>
    binary<span class="token punctuation">[</span>margins<span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token number">1</span> <span class="token comment">#将所有margin大于0的元素置为1，便于计数</span>
    row_sum<span class="token operator">=</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>binary<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment">#得到每行margin大于0的类别数(循环实现中的count)</span>
    binary<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">,</span>y<span class="token punctuation">]</span><span class="token operator">=</span><span class="token operator">-</span>row_sum 
    <span class="token comment">#现在正确类别对应的元素值即为-count，margin大于0类别对应的元素值为1，其余为0</span>
    dW<span class="token operator">=</span>X<span class="token punctuation">.</span>T<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>binary<span class="token punctuation">)</span><span class="token operator">/</span>N 
    dW<span class="token operator">+=</span><span class="token number">2</span><span class="token operator">*</span>reg<span class="token operator">*</span>W

    <span class="token keyword keyword-return">return</span> loss<span class="token punctuation">,</span> dW
</code></pre><p>具体细节已经通过注释说明，主要思路是通过矩阵变换实现计算。<br>
计算损失函数只需要保留矩阵中margin&gt;0的部分再求和即可。计算梯度时，通过矩阵变换将正确类别对应地元素值变为-count，margin&gt;0类别对应元素值为1，通过矩阵乘法直接实现梯度计算。</p>
<h4 id="3-在这里提交ipynb中的相关检查结果不占额外分数但这是判断上面的实现是否正确的重要依据">3, 在这里提交ipynb中的相关检查结果（不占额外分数，但这是判断上面的实现是否正确的重要依据. </h4>
<p><strong>梯度检查结果</strong></p>
<p><img src="image-2.png" alt="alt text"></p>
<p><strong>SVM损失检查结果</strong></p>
<p><img src="image-3.png" alt="alt text"></p>
<p><strong>SVM梯度检查结果</strong></p>
<p><img src="image-4.png" alt="alt text"></p>
<h3 id="二-实现sgd">二、实现SGD </h3>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-class">class</span> <span class="token class-name">LinearClassifier</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>W <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword keyword-def">def</span> <span class="token function">train</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        X<span class="token punctuation">,</span>
        y<span class="token punctuation">,</span>
        learning_rate<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">,</span>
        reg<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">,</span>
        num_iters<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
        batch_size<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
        verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        num_train<span class="token punctuation">,</span> dim <span class="token operator">=</span> X<span class="token punctuation">.</span>shape
        num_classes <span class="token operator">=</span> <span class="token punctuation">(</span>
            np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
        <span class="token punctuation">)</span>
        <span class="token keyword keyword-if">if</span> self<span class="token punctuation">.</span>W <span class="token keyword keyword-is">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>W <span class="token operator">=</span> <span class="token number">0.001</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
        loss_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword keyword-for">for</span> it <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_iters<span class="token punctuation">)</span><span class="token punctuation">:</span>
            X_batch <span class="token operator">=</span> <span class="token boolean">None</span>
            y_batch <span class="token operator">=</span> <span class="token boolean">None</span>

            <span class="token comment"># 通过放回采样随机选取batch_size个样本（通过随机下标实现）</span>
            index<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>num_train<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>replace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            X_batch<span class="token operator">=</span>X<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
            y_batch<span class="token operator">=</span>y<span class="token punctuation">[</span>index<span class="token punctuation">]</span>

            <span class="token comment"># 评估损失和梯度</span>
            loss<span class="token punctuation">,</span> grad <span class="token operator">=</span> self<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>X_batch<span class="token punctuation">,</span> y_batch<span class="token punctuation">,</span> reg<span class="token punctuation">)</span>
            loss_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

            self<span class="token punctuation">.</span>W <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> grad

            <span class="token keyword keyword-if">if</span> verbose <span class="token keyword keyword-and">and</span> it <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">"iteration %d / %d: loss %f"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>it<span class="token punctuation">,</span> num_iters<span class="token punctuation">,</span> loss<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword keyword-return">return</span> loss_history

    <span class="token keyword keyword-def">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>X<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>W<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token keyword keyword-return">return</span> y_pred
</code></pre><p>每一次循环中，在所有样本中随机挑选batch_size个样本进行损失评估并计算梯度，最后通过学习率和梯度更新权重。<br>
预测时通过<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo separator="true">⋅</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">X·W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>计算每类得分，从中选取得分最高的类别作为预测输出，存储在y_pred中。</p>
<h3 id="三-利用验证集做超参数调优">三、利用验证集做超参数调优 </h3>
<p>表格记录（5*5），可以自己尝试不同的组合 （10%）</p>
<table>
<thead>
<tr>
<th style="text-align:left">学习率 \ 正则化强度</th>
<th style="text-align:left">2.5e4</th>
<th style="text-align:left">3e4</th>
<th style="text-align:left">1e4</th>
<th style="text-align:left">1.5e4</th>
<th style="text-align:left">2e4</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>1.5e-7</strong></td>
<td style="text-align:left">0.366000</td>
<td style="text-align:left">0.368000</td>
<td style="text-align:left">0.314000</td>
<td style="text-align:left">0.372000</td>
<td style="text-align:left">0.344000</td>
</tr>
<tr>
<td style="text-align:left"><strong>2e-7</strong></td>
<td style="text-align:left">0.366000</td>
<td style="text-align:left">0.365000</td>
<td style="text-align:left">0.343000</td>
<td style="text-align:left">0.351000</td>
<td style="text-align:left">0.376000</td>
</tr>
<tr>
<td style="text-align:left"><strong>2.5e-7</strong></td>
<td style="text-align:left">0.366000</td>
<td style="text-align:left">0.340000</td>
<td style="text-align:left">0.344000</td>
<td style="text-align:left">0.356000</td>
<td style="text-align:left">0.361000</td>
</tr>
<tr>
<td style="text-align:left"><strong>2.25e-7</strong></td>
<td style="text-align:left">0.355000</td>
<td style="text-align:left">0.350000</td>
<td style="text-align:left">0.344000</td>
<td style="text-align:left">0.354000</td>
<td style="text-align:left">0.373000</td>
</tr>
<tr>
<td style="text-align:left"><strong>2.75e-7</strong></td>
<td style="text-align:left">0.328000</td>
<td style="text-align:left">0.371000</td>
<td style="text-align:left">0.340000</td>
<td style="text-align:left">0.344000</td>
<td style="text-align:left">0.349000</td>
</tr>
</tbody>
</table>
<p>最优的结果的loss曲线截图和正确率截图（5%）</p>
<p><strong>最优结果的loss曲线截图</strong></p>
<p><img src="image-6.png" alt="alt text"></p>
<p><strong>最佳参数及正确率截图</strong></p>
<p><img src="image-5.png" alt="alt text"></p>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>